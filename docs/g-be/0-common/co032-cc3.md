---
sidebar_position: 32
---

# Cloud SW 아키텍처 패턴:Performance Patterns

- [Cloud SW 아키텍처 패턴:Performance Patterns](#cloud-sw-아키텍처-패턴performance-patterns)
  - [Performance Patterns for Data Intensive Systems](#performance-patterns-for-data-intensive-systems)
  - [Map Reduce Pattern](#map-reduce-pattern)
    - [대용량 데이터 처리의 문제점](#대용량-데이터-처리의-문제점)
    - [맵리듀스의 사용 사례](#맵리듀스의-사용-사례)
    - [기본 구조](#기본-구조)
    - [예시](#예시)
    - [아키텍처 구조](#아키텍처-구조)
    - [이점](#이점)
    - [실패 및 복구 전략](#실패-및-복구-전략)
    - [고려점](#고려점)
  - [Saga Pattern](#saga-pattern)
  - [Transactional Outbox Pattern](#transactional-outbox-pattern)
  - [Materialized View Pattern](#materialized-view-pattern)
  - [CQRS Pattern](#cqrs-pattern)
  - [Event Sourcing Pattern](#event-sourcing-pattern)


## Performance Patterns for Data Intensive Systems  
---

데이터 집약 시스템을 위한 성능 패턴을 도입으로 얻는 이점은 무엇일까?  


<br/>

## Map Reduce Pattern
---

### 대용량 데이터 처리의 문제점  

대용량 데이터 세트 처리의 문제점은 데이터 처리를 위해서 수백~수천 대의 머신에 분산처리 시켜야 하는 점이다.  
- 데이터 병렬화, 데이터 분산 배포, 결과 추합
- 실행 예약, 실패 처리, 복구 문제
- 많은 처리 소스 코드 및 인프라 구성  

맵리듀스 패턴을 사용하면, 아키텍처의 변경없이 많은 양의 데이터를 처리할 수 있는 시스템이 구성된다.  


### 맵리듀스의 사용 사례  
- 머신러닝
- 로그 파일 필터 및 분석
- 역색인 구성
- 웹링크 그래프 순회
- 분산 정렬  


### 기본 구조
![](./img/co14.png)  

Input data: key-value 쌍으로 구성된 데이터를 입력  
1. Map : Map를 통과하면 중간 key-value쌍이 나오게 된다.  
2. intermediate data : Map 중간 key-value 결과물 
3. Reduce : Reduce 함수에서 중간 key-value를 grouping하고(정렬) Reduce 로직 수행 후 최종 데이터를 출력한다.
Output data : 최종데이터   
* 사실상 위 구조만 봤을때는 잘 이해되지 않는다.    

### 예시 
![](./img/co15.png)  

Goal : 수많은 파일들을 분석해서, 특정 단어의 수를 카운트 하자.  

Input data: key는 파일이름, value는 파일 내용물   

1. Map : text-file을 대상으로만 단어의 갯수들을 출력한다. 이는 key-value쌍이다.    
2. intermediate data : 합산되지 않은 파일들의 단어수들의 key-value 데이터들 

![](./img/co17.png)  
3. Reduce : 단어순으로 정렬 후 각 단어들의 갯수를 구하여 최종 데이터를 출력한다.    
- *리듀스 함수를 통과시키는데 key에 대해서 반복자를 돌린다. 중간키에 대한 값이 많아서 메모리에 한번에 로드 불가능   

Output data : 단어 - 갯수의 리스트


### 아키텍처 구조

![](./img/co16.png)  

1.마스터 노드 
- 전체 MapReduce 예약 및 컨트롤  
- 전체 데이터를 청크단위로 나누어서, Map Workder들에게 할당한다. ( 실제 데이터 주는것이 아닌 임무를 부여)  

2.Map Workers  
- Map 함수를 실행하는 수백 ~ 수천개의 컴퓨터  
- 그냥 데이터를 저장하지 않고, Region을 분리해서 저장한다.  
- Region = hash(key) mod R : 을 통해서 어떤 Region에 저장할지 결정 가능하다.  

3.Reduce Workers
- 마스터는 각 Region을 담당하고 있는 워커에게 작업을 분배한다.
- 리듀스 워커가 데이터를 읽어간다. 
- 키를 그룹 및 정렬하는 과정 (셔플링) > Reduce 연산을 수행  

### 이점  

- 같은 SW아키텍처를 재활용할 수 있다. Map,Reduce함수만 바꾸면 된다. 
- 테스크의 스케일링이 가능.  
- 많은 워커에게 평행하게 작업 분배 가능    
- 짧은 시간안에 대용량의 데이터를 처리할 수 있음.  


### 실패 및 복구 전략
- 마스터가 리듀스 워커들을 관찰하며, 실패한 작업을 다시 다른 워커에게 할당
- 맵 워커가 실패한 경우도 다른 워커에게 작업을 할당하며 이때 바뀐 중간 key-value 값위치도 리듀스워커에게 알려야한다.  
- 마스터 워커가 장애날 확률은 적지만, 작업에 대한 상태를 스냅샷을 두거나 백업 마스터를 둔다.  

### 고려점
- 직접 Map,Reduce 아키텍처를 구성할 일은 없다. 
- 오픈소스/클라우드 서비스 이용한다.  
- 클라우드 환경을 이용해서 필요한 만큼 컴퓨터를 대여하고 반납한다.  
  - ㄴ ( on demand | on scheduled Batch )
- 시스템은 구성을 신경스지 않고, 비즈니스에 집중 가능하다.
  - ㄴ 데이터모델링, map-reduce 모델링, execution parameters 정의 ..등  

<br/>

## Saga Pattern
---


[ 예시 - 티켓 판매 서비스 ]
Order Service : 좌석이 예약된 상태로 DB를 업데이트한다.  
트랜젝션이 실패하지 않은경우에는 다른 사용자가 이용 불가  

보상 트렌젝션 : pending상태를 되돌리는 트렌젝션  
Pivot Operation : 성공상태를 위해 pending상태를 바꾸는 작업들  


## Transactional Outbox Pattern


단일 트랜젝션으로 만드는 방법 

[ 문제점 - outbox service가 메시지를 두번 보내는 경우 ]

메시지 중복이 되더라도 괜찮은 경우 
- 멱등 연산인 경우
- 결제처럼 중복이 일어나면 안되는 경우 - 멱등연산으로 만들면된다. 
- *결제 ID를 부여

[ 문제점 - atomic transaction을 DB에서 지원하지 않는 경우 nosql ]
- document model에 outbox 데이터 자체를 추가하면 된다. 

[ 문제점 - 이벤트의 순서 ]
- outbox테이블에 시퀀스 ID를 부여하는 것 
- 항상 ID가 낮은 순서대로 메시지를 읽어서 처리해야 한다.  

## Materialized View Pattern


Raw Data Table이 업데이트 되면, View 테이블을 즉시 혹은 스케쥴링된 시간에 업데이트 가능하다.

[ 예시 ]
온라인 교옥 플랫폼

[ 방법 ]
db 테이블로 저장 
redis 로 저장

[ 코멘트 ]
DB조회가 느린 경우 말고도, 서드파티 API가느린 경우에도 사용할 수 있겠다. 

## CQRS Pattern

Command and Query Responsibility Segregation 

[ 트레이드 오프 ]
복잡한 시스템

[ 사례 ]

후기를 읽는 서비스
- 읽기에 최적화되어있다. 
- 특별한 비즈니스 로직 유효성 검사 등 필요없고, 퍼블릭에 공개가능한 데이터만 존재한다.  

리뷰는 비교적 실시간 업데이트를 진행하고 
상품의 평균 리뷰는 스케쥴링을 통해 제공 

[ CQRS + Materialized View ]

1. Message Queue 데이터 싱크
2. Cloud Function 데이터 싱크

## Event Sourcing Pattern



